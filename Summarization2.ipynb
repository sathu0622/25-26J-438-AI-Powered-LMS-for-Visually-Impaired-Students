{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPE9/3QTvCJMaPa1yW31/jm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d4e8efce26a46b1b849726f3b3a2f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2693286da78c4cb8af59abd304531ad7",
              "IPY_MODEL_925e858f507d44239b5b1d68286ba41e",
              "IPY_MODEL_5b8721a86e304f00815870a371fb9b3a"
            ],
            "layout": "IPY_MODEL_902795c32d4b41a9b06b4947068aeb65"
          }
        },
        "2693286da78c4cb8af59abd304531ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4608500a46145068b8d5235ff9440e2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a66834c9b32641b9a1d28eada65bd41f",
            "value": "Map:‚Äá100%"
          }
        },
        "925e858f507d44239b5b1d68286ba41e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf774652cf914c3a859516cf26dd9954",
            "max": 360,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58a560bb765f4e6bb2622e0da8ec4bf1",
            "value": 360
          }
        },
        "5b8721a86e304f00815870a371fb9b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b958a1b361eb4d2babd702cd4c83dbde",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c38986e6f1fd480a8a1b33873a12f536",
            "value": "‚Äá360/360‚Äá[00:12&lt;00:00,‚Äá27.93‚Äáexamples/s]"
          }
        },
        "902795c32d4b41a9b06b4947068aeb65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4608500a46145068b8d5235ff9440e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a66834c9b32641b9a1d28eada65bd41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf774652cf914c3a859516cf26dd9954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58a560bb765f4e6bb2622e0da8ec4bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b958a1b361eb4d2babd702cd4c83dbde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c38986e6f1fd480a8a1b33873a12f536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e499f94112b84d6983febd8af53bbfe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc7a4ea39994447d9ebe08f634b6a393",
              "IPY_MODEL_40b9afd395b443e5a9c936c5affbeb26",
              "IPY_MODEL_0b62636b677c43629c42c77ae0c4470f"
            ],
            "layout": "IPY_MODEL_a0a62353f58242748ee18e5acdd5b148"
          }
        },
        "dc7a4ea39994447d9ebe08f634b6a393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f556099fe46b4ea191758d4afb338669",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e1b9e7d95b5649f396f7c66c3cba7f24",
            "value": "Map:‚Äá100%"
          }
        },
        "40b9afd395b443e5a9c936c5affbeb26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e97677858e64fbbade7965df6980187",
            "max": 41,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ebc36f0d2164bdca2104d295e0aa8bc",
            "value": 41
          }
        },
        "0b62636b677c43629c42c77ae0c4470f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_060e61d893be434db8234884ddca55d9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_77431b078cfc4991ac4abe3b81ce0dc5",
            "value": "‚Äá41/41‚Äá[00:00&lt;00:00,‚Äá54.91‚Äáexamples/s]"
          }
        },
        "a0a62353f58242748ee18e5acdd5b148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f556099fe46b4ea191758d4afb338669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1b9e7d95b5649f396f7c66c3cba7f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e97677858e64fbbade7965df6980187": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ebc36f0d2164bdca2104d295e0aa8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "060e61d893be434db8234884ddca55d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77431b078cfc4991ac4abe3b81ce0dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sathu0622/25-26J-438-AI-Powered-LMS-for-Visually-Impaired-Students/blob/AI-Powered-System-for-Voice-Based-Resource-Type-Summarization-of-Historical-Content-for-VIS/Summarization2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== 2Ô∏è‚É£ Mount Google Drive =====================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ===================== 3Ô∏è‚É£ Load Dataset =====================\n",
        "import json\n",
        "from datasets import Dataset\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/history_dataset.json\"  # update path\n",
        "\n",
        "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "dataset = Dataset.from_list([{\n",
        "    'text': item['content'],\n",
        "    'summary': item['target_summary'],\n",
        "    'source_type': item['source_type']\n",
        "} for item in data])\n",
        "\n",
        "dataset = dataset.train_test_split(test_size=0.1)\n",
        "train_dataset = dataset['train']\n",
        "test_dataset = dataset['test']\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}, Test samples: {len(test_dataset)}\")\n",
        "\n",
        "# ===================== 4Ô∏è‚É£ Tokenization =====================\n",
        "from transformers import BartTokenizer\n",
        "\n",
        "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "max_input_length = 1024\n",
        "max_target_length_map = {'newspaper': 120, 'magazine': 220, 'book': 400}\n",
        "\n",
        "def preprocess(batch):\n",
        "    max_target_lengths = [max_target_length_map.get(src, 150) for src in batch['source_type']]\n",
        "\n",
        "    inputs = tokenizer(batch['text'], max_length=max_input_length, truncation=True, padding=\"max_length\")\n",
        "    targets = [tokenizer(batch['summary'][i], max_length=max_target_lengths[i], truncation=True, padding=\"max_length\")\n",
        "               for i in range(len(batch['summary']))]\n",
        "\n",
        "    batch[\"input_ids\"] = inputs[\"input_ids\"]\n",
        "    batch[\"attention_mask\"] = inputs[\"attention_mask\"]\n",
        "    batch[\"labels\"] = [t['input_ids'] for t in targets]\n",
        "    return batch\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess, batched=True)\n",
        "test_dataset = test_dataset.map(preprocess, batched=True)\n",
        "\n",
        "# ===================== 5Ô∏è‚É£ Load Model =====================\n",
        "from transformers import BartForConditionalGeneration\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "# ===================== 6Ô∏è‚É£ Check GPU =====================\n",
        "import torch\n",
        "use_fp16 = torch.cuda.is_available()\n",
        "print(f\"GPU available: {use_fp16}\")\n",
        "\n",
        "# ===================== 7Ô∏è‚É£ Training Arguments =====================\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/history_summary_model\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    logging_steps=10,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    learning_rate=3e-5,\n",
        "    weight_decay=0.01,\n",
        "    fp16=use_fp16\n",
        ")\n",
        "\n",
        "# ===================== 8Ô∏è‚É£ Data Collator =====================\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# ===================== 9Ô∏è‚É£ Trainer =====================\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "# ===================== üîü Train =====================\n",
        "trainer.train()\n",
        "\n",
        "# ===================== 1Ô∏è‚É£1Ô∏è‚É£ Save Final Model =====================\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "print(f\"Model saved to {output_dir}\")\n",
        "\n",
        "# ===================== 1Ô∏è‚É£2Ô∏è‚É£ Generate Summaries =====================\n",
        "def summarize(text, source_type='magazine'):\n",
        "    max_length = max_target_length_map.get(source_type, 150)\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=max_input_length, truncation=True)\n",
        "    summary_ids = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=max_length,\n",
        "        min_length=int(max_length*0.5),\n",
        "        length_penalty=2.0,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Example usage\n",
        "example_text = train_dataset[0]['text']\n",
        "example_type = train_dataset[0]['source_type']\n",
        "print(\"Generated Summary:\")\n",
        "print(summarize(example_text, source_type=example_type))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4d4e8efce26a46b1b849726f3b3a2f37",
            "2693286da78c4cb8af59abd304531ad7",
            "925e858f507d44239b5b1d68286ba41e",
            "5b8721a86e304f00815870a371fb9b3a",
            "902795c32d4b41a9b06b4947068aeb65",
            "e4608500a46145068b8d5235ff9440e2",
            "a66834c9b32641b9a1d28eada65bd41f",
            "bf774652cf914c3a859516cf26dd9954",
            "58a560bb765f4e6bb2622e0da8ec4bf1",
            "b958a1b361eb4d2babd702cd4c83dbde",
            "c38986e6f1fd480a8a1b33873a12f536",
            "e499f94112b84d6983febd8af53bbfe7",
            "dc7a4ea39994447d9ebe08f634b6a393",
            "40b9afd395b443e5a9c936c5affbeb26",
            "0b62636b677c43629c42c77ae0c4470f",
            "a0a62353f58242748ee18e5acdd5b148",
            "f556099fe46b4ea191758d4afb338669",
            "e1b9e7d95b5649f396f7c66c3cba7f24",
            "2e97677858e64fbbade7965df6980187",
            "9ebc36f0d2164bdca2104d295e0aa8bc",
            "060e61d893be434db8234884ddca55d9",
            "77431b078cfc4991ac4abe3b81ce0dc5"
          ]
        },
        "id": "qDr2nhIn0J8E",
        "outputId": "e206b0bc-24b3-4e99-c3af-c4d7829d26b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Train samples: 360, Test samples: 41\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/360 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d4e8efce26a46b1b849726f3b3a2f37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/41 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e499f94112b84d6983febd8af53bbfe7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3014397194.py:84: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msathushan622\u001b[0m (\u001b[33msathushan622-sliit\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251117_080740-g1ef0tit</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sathushan622-sliit/huggingface/runs/g1ef0tit' target=\"_blank\">fresh-snowflake-1</a></strong> to <a href='https://wandb.ai/sathushan622-sliit/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sathushan622-sliit/huggingface' target=\"_blank\">https://wandb.ai/sathushan622-sliit/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sathushan622-sliit/huggingface/runs/g1ef0tit' target=\"_blank\">https://wandb.ai/sathushan622-sliit/huggingface/runs/g1ef0tit</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='540' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [540/540 06:03, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.898700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.549800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.349400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.085400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.739100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.841100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.915200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.925800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.974800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.945000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.806600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.746600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.785100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.654200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.786100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.569800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>1.724900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.499900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>1.259900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.190800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.120800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.933500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.996100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.949100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.136100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.190200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>1.225100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.965000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>1.118800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.240000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>1.007500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>1.104400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>1.224100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.970600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.914500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>1.053900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.856500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.733500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.671900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.709200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.569600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.676600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.646400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.801300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.820600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.810300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.830800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.774300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.753200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.196500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.783500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.775500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.733800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.699500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:3918: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/history_summary_model\n",
            "Generated Summary:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3014397194.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0mexample_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generated Summary:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexample_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3014397194.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(text, source_type)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_target_length_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_input_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     summary_ids = model.generate(\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"encoder_outputs\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m             \u001b[0;31m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2465\u001b[0;31m             model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0m\u001b[1;32m   2466\u001b[0m                 \u001b[0minputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_input_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0membed_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_positions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2544\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2546\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== 0Ô∏è‚É£ Install Dependencies =====================\n",
        "!pip install -q evaluate rouge_score transformers\n",
        "\n",
        "# ===================== 1Ô∏è‚É£ Load the Saved Model =====================\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "import torch\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/history_summary_model\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_path)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_path)\n",
        "\n",
        "# Use GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "print(\"Model loaded. Using device:\", device)\n",
        "\n",
        "# ===================== 2Ô∏è‚É£ Import Evaluation Library =====================\n",
        "import evaluate\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "# ===================== 3Ô∏è‚É£ Define Summarization Function =====================\n",
        "max_target_length_map = {'newspaper': 120, 'magazine': 220, 'book': 400}\n",
        "\n",
        "def summarize(text, source_type='magazine'):\n",
        "    max_length = max_target_length_map.get(source_type, 150)\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n",
        "    summary_ids = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=max_length,\n",
        "        min_length=int(max_length*0.5),\n",
        "        length_penalty=2.0,\n",
        "        num_beams=4,\n",
        "        no_repeat_ngram_size=3,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# ===================== 4Ô∏è‚É£ Generate Summaries on Test Dataset =====================\n",
        "generated_summaries = []\n",
        "reference_summaries = []\n",
        "\n",
        "for example in test_dataset:\n",
        "    pred = summarize(example['text'], example['source_type'])\n",
        "    generated_summaries.append(pred)\n",
        "    reference_summaries.append(example['summary'])\n",
        "\n",
        "# ===================== 5Ô∏è‚É£ Print Some Examples =====================\n",
        "for i in range(5):\n",
        "    print(f\"--- Example {i+1} ---\")\n",
        "    print(\"Source Type:\", test_dataset[i]['source_type'])\n",
        "    print(\"Original Text:\", test_dataset[i]['text'][:500], \"...\")\n",
        "    print(\"Target Summary:\", reference_summaries[i])\n",
        "    print(\"Generated Summary:\", generated_summaries[i])\n",
        "    print(\"\\n\")\n",
        "\n",
        "# ===================== 6Ô∏è‚É£ Calculate ROUGE Scores =====================\n",
        "results = rouge.compute(predictions=generated_summaries, references=reference_summaries)\n",
        "print(\"ROUGE Scores:\")\n",
        "for key in results:\n",
        "    print(f\"{key}: {results[key].mid.fmeasure:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jY2TVdeI4tf3",
        "outputId": "21809cb8-7282-4257-da56-d62288dca83f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Model loaded. Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py:1733: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Example 1 ---\n",
            "Source Type: magazine\n",
            "Original Text: The Seventh Dragoon Guards made one of the last charges of the First World War at 10.30am on 11 November 1918, galloping forward and capturing the bridge at Lessines in the Picardy region of Belgium. Fighting officially ended at 11am on the same day, when the Armistice was signed. On hearing the news, the Fifth Dragoon Guards  official war diary described the celebration as the regiment prepared for a  triumphal march into Germany . While the official diary could easily be written in a celebrato ...\n",
            "Target Summary: The First World War‚Äôs thunderous end arrived with a stark paradox on November 11, 1918. Even as the official Armistice was hours away, the Seventh Dragoon Guards made one of the conflict's last charges, capturing a bridge at Lessines. While official war diaries optimistically spoke of triumphal marches into Germany and newspapers at home erupted in jubilant celebration, the news of peace was often met with a far more complex, frequently muted, emotional landscape among the serving troops themselves.\n",
            "\n",
            "Many contemporary military diaries, surprisingly, offered little more than a factual note of the cessation of hostilities, devoid of the expected elation. The First West Yorkshire Regiment, for instance, recorded the news as being \"taken very quietly.\" This quietude stemmed from years of weary endurance, the omnipresent shadow of death, and a pervasive uncertainty about the future. For soldiers like Private Thomas Reginald Warner, the war's seemingly endless nature had ingrained a day-by-day existence, making the Armistice almost incomprehensible. Richard Enden similarly recalled relief, but \"no real excitement or jubilation,\" recognizing that an entire way of life had ended.\n",
            "\n",
            "This initial quiet often evolved into a profound \"silence\" among returning veterans, a phenomenon noted by historians. Later memoirs, penned decades after the conflict, often painted a more somber picture. Captain Herman Marsden, in his 1976 memoirs, described Armistice Day as passing \"unnoticed, without rejoicing or celebration,\" leaving only \"sad and morbid memories\" for survivors. Poet Robert Graves, in his 1929 \"Goodbye To All That,\" recounted cursing and sobbing over lost friends rather than celebrating. These powerful, reflective accounts, often mirroring the burgeoning anti-war sentiment of the 1920s and 30s, acknowledged the passage of time had shaped their understanding, yet deeply conveyed the psychological toll of war.\n",
            "\n",
            "For countless soldiers, the Armistice did not signal an immediate end to hardship. Demobilization was a slow, often frustrating process, with many remaining on the front lines amidst lingering dangers, or marching into Germany for months. The grand promise of a \"land fit for heroes\" frequently dissolved into the grim reality of a post-war Britain grappling with economic depression and widespread unemployment. Veterans, despite their valor and military honours, often found their wartime experiences a \"definite handicap\" in the fiercely competitive civilian job market, as Marsden vividly recounted.\n",
            "\n",
            "Furthermore, millions bore the indelible physical and mental scars of the conflict. The Ministry of Pensions provided some aid, yet support was often insufficient or hard-won. While some, like Private John Cook, received lifelong pensions for severe injuries, others, like Private Joe Bradley for trench fever, were granted only temporary, meagre sums, or, like Private Sydney Round, were outright denied, their ailments deemed \"not aggravated by the war.\" The devastating psychological trauma of \"shell shock\" left many with \"little breakdowns,\" affecting entire families and, in severe cases, leading to institutionalization in \"lunatic asylums\" for decades. For these institutionalized men, the Armistice meant tragically little, as they continued to fight a war that would never truly end.\n",
            "\n",
            "As the years passed, public commemoration of Armistice Day subtly shifted. While initial reactions from veterans highlighted a complex array of emotions, the focus gradually moved from the inconvenient plight of living, often struggling, ex-servicemen to the revered memory of the \"valiant dead.\" A century on, it remains vital to remember the full spectrum of experiences surrounding the Armistice and the enduring, profound legacy of the war on those who survived to carry its scars.\n",
            "Generated Summary: 1.  The First World War ended officially at 11am on November 11, 1918, with the Armistice signed at 11:11 a.m. local time, marking the end of the Great War.\n",
            "2.  While official diaries, such as the Fifth Dragoon Guards' celebration, often depicted a triumphant march into Germany, soldiers' personal accounts reveal a more somber, reverent approach to peace, often characterized by quiet reflection and thanksgiving.\n",
            "3.  Historians have studied personal testimonies and diaries to understand the social and military aspects of the war, examining how soldiers' reactions to the Armistsice evolved over the century, reflecting distinct national attitudes and societal beliefs.\n",
            "4.  These varied accounts reveal the varied reactions of soldiers, reflecting their varied experiences on the front lines and upon their return to civilian life.\n",
            "5.  Despite these personal accounts, the official narrative often paints a somber picture, contrasting with the more celebratory tone of the First West Yorkshire Regiment's war diary, which described the news as \"t\n",
            "\n",
            "\n",
            "--- Example 2 ---\n",
            "Source Type: magazine\n",
            "Original Text: Why has podcasting become such a natural home for history? Ad Perhaps it s because the medium is so well-suited to storytelling. Podcasts invite listeners into the past through conversation and narrative   and when done right, this can bring history to life in a way that few other forms can match. But history podcasting has also become a crowded field, overflowing with choice and variety. With so many voices vying for attention, choosing where to spend your listening hours can feel like its own  ...\n",
            "Target Summary: Podcasting has emerged as a vibrant and natural home for history, transforming the past into compelling narratives and dynamic conversations. While the landscape is rich with choice, several standout shows offer distinctive journeys through time, each with a unique voice and style.\n",
            "\n",
            "Dr. Kate Lister's \"Betwixt the Sheets\" fearlessly unearths the intimate and often-overlooked aspects of human history, from medieval sex manuals to Cold War sexual politics. Blending academic rigor with refreshing irreverence, it spotlights marginalized voices and reveals the profound societal intersections of sexuality.\n",
            "\n",
            "A true trailblazer, Dan Carlin's \"Hardcore History\" redefines audio storytelling with epic, immersive narratives that can captivate listeners for hours. Carlin masterfully plunges audiences into pivotal moments like the Mongol conquests or Verdun's trenches, crafting monumental, irregularly released episodes that offer unforgettable historical journeys.\n",
            "\n",
            "For a compelling exploration of global power, \"Empire,\" co-hosted by historian William Dalrymple and journalist Anita Anand, offers astute analysis of empires and their enduring legacies. Their combined expertise weaves analytical depth with engaging storytelling, providing nuanced perspectives on world-shaping events and their influential figures.\n",
            "\n",
            "Paul Cooper's \"Fall of Civilizations\" presents a profound, reflective meditation on the collapse of great societies, from the Maya to the Roman West. Through meticulous research, evocative narration, and immersive soundscapes, it not only uncovers reasons for decline but also extracts timeless lessons these historical shifts offer humanity.\n",
            "\n",
            "Vividly reclaiming the millennium following Rome's fall, \"Gone Medieval,\" presented by Matt Lewis and Dr. Cat Jarman, showcases the unexpected vibrancy of the Middle Ages. Blending insights on warfare and politics with bioarchaeological discoveries, it transcends clich√©s to explore everything from Viking sagas to intricate illuminated manuscripts.\n",
            "\n",
            "\"HistoryExtra\" stands as a venerable and prolific podcast, delivering nearly daily, insightful conversations with leading historians worldwide. Spanning all eras from prehistory to modern times, it keeps listeners at the forefront of new scholarship, offering deep dives and special series on intriguing historical questions.\n",
            "\n",
            "The long-standing BBC institution \"In Our Time,\" hosted by Melvyn Bragg (soon to depart), convenes expert scholars for rigorous discussions on single historical topics. Its unique format skillfully unpacks scholarly disagreements, making complex subjects engaging and accessible through a vast and revered archive spanning decades.\n",
            "\n",
            "\"The Rest is History,\" co-hosted by prominent historians Dominic Sandbrook and Tom Holland, has become a true podcasting phenomenon. Their magnetic chemistry, intellectual curiosity, and witty rapport drive explorations from singular figures to sprawling multi-part series, making history both entertaining and profoundly engaging.\n",
            "\n",
            "NPR's \"Throughline\" masterfully connects the present to its historical roots, dissecting contemporary issues like immigration or oil politics by tracing their centuries-old origins. With rich production, archival audio, and insightful interviews, it blends journalism and history to illuminate how past events shape our world today, with both American and international scope.\n",
            "\n",
            "Finally, \"You're Dead to Me,\" with host Greg Jenner, brings a signature blend of robust research and infectious humor to the airwaves. This accessible yet well-researched BBC production makes history genuinely fun, balancing seriousness with entertainment while exploring figures from Joan of Arc to the Harlem Renaissance, often spotlighting overlooked narratives.\n",
            "Generated Summary: Pundits like Dan Carlin's Hardcore History and Dr. Kate Lister's \"Betwixt the Sheets\" aim to immerses listeners in the intimate and often overlooked aspects of the human past, exploring topics ranging from medieval sex manuals to the history of drag and the Cold War. The \"Empire\" podcast, co-founded by William Dalrymple and Anita Anand, delves into the history and legacy of global empires, highlighting Winston Churchill, Franklin Roosevelt, and Joseph Stalin's interactions at the 1945 Yalta Conference. \"Gone Medieval\" explores the millennium following the fall of the Western Roman empire, exploring subjects such as Viking voyages and illuminated manuscripts, while \"Extra History\" offers insightful conversations with leading historians from across the globe.\n",
            "\n",
            "\n",
            "--- Example 3 ---\n",
            "Source Type: magazine\n",
            "Original Text: The torched city burns as thousands of imperial troops pillage Rome on 6 May 1527, as depicted by a 16th or 17th-century Italian artist. (AKG) Ad 4 May 1926: The General Strike fails to paralyse Britain To many people, the first full day of the General Strike on 4 May 1926 represented a turning point in history. After years of mounting tension between employers and unions, particularly in the coal industry, the Trades Union Congress finally ordered its members out. On that first morning, docks,  ...\n",
            "Target Summary: Across the annals of history, May emerges as a month punctuated by both profound shifts and dramatic upheavals, from the barbaric sack of an ancient city to the quiet launch of a communication revolution.\n",
            "\n",
            "On **6 May 1527**, Rome suffered a catastrophic assault from an unpaid, uncontrollable imperial army. Their commander, the Duke of Bourbon, could only avert mutiny by promising his 20,000 soldiers the city's riches. The duke's immediate death in the assault shattered all discipline, unleashing an unbridled orgy of plunder and destruction. Imperial troops ravaged the city, slaughtering the Swiss Guard at the Vatican as Pope Clement VII barely escaped. Churches, tombs, and homes were desecrated, and approximately 12,000 lives extinguished, leaving an indelible scar on European memory ‚Äì a testament to brutal, chaotic warfare.\n",
            "\n",
            "Decades of simmering industrial tension erupted into Britain's General Strike on **4 May 1926**, sparking fears of revolution. As docks, factories, and rail yards fell silent nationwide, conservative media warned of a Bolshevik uprising. An eerie unreality gripped the country: public transport ceased, factory chimneys stood cold, yet roads filled with pedestrians and surprising acts of generosity. Despite government troop deployments, the anticipated class warfare never materialized. After nine days, the strike quietly dissipated, becoming a \"non-event\" compared to global turmoil. King George V, who empathized with the workers, ultimately hailed it as a profound testament to British unity.\n",
            "\n",
            "The age of modern communication dawned on **6 May 1840** with Rowland Hill's revolutionary Penny Black. Haunted by childhood postal payment woes, Hill, a visionary reformer, conceived of universal penny postage paid in advance via a small, adhesive 'bit of paper.' Adorned with Queen Victoria's portrait, the world's first postage stamp became an instant sensation. Despite initial humorous trepidation over its \"glutinous wash,\" presses soon churned out 600,000 stamps daily. More than a convenience, the Penny Black swiftly became a cherished icon and a proud symbol of British ingenuity.\n",
            "\n",
            "A pivotal, humiliating chapter in Plantagenet history unfolded on **14 May 1264**, at the Battle of Lewes. For years, King Henry III had clashed with his barons, notably the formidable Simon de Montfort, a staunch defender of Magna Carta. Cornered at Lewes, Montfort's devout preparations preceded a decisive clash where the royal army's fatal indiscipline proved its undoing. Despite a spirited cavalry charge by Prince Edward, Montfort's forces ruthlessly crushed the disarrayed king's army. Henry and Edward were forced to retreat, enduring the ultimate humiliation the following day: formal surrender to Simon de Montfort.\n",
            "\n",
            "The enduring siege of Mafeking, a beacon of British tenacity during the disastrous early Boer War, finally broke on **16 May 1900**. For over 200 days, 1,500 troops under Colonel Robert Baden-Powell bravely withstood a vastly superior Boer force, their ingenious tactics and even Sunday cricket captivating the public. As the nation held its breath for news of relief, it arrived late on the 16th ‚Äì seven dusty cavalrymen met with an understated welcome. By dawn, unbridled joy erupted in Mafeking's streets, a prelude to a week of hysterical national celebrations, hailing the defenders' resilience.\n",
            "\n",
            "On **16 May 1703**, Russia's audacious young emperor, Peter the Great, literally broke ground for a new city. Having fought his way to the Baltic, Peter, with a legendary cut of turf on a marshy Neva island, declared, \"Here, shall be a town.\" Against all odds ‚Äì ongoing war and an unforgiving environment ‚Äì his ambition knew no bounds. Within months, a log house and the mighty Peter and Paul Fortress emerged. Yet, St Petersburg's birth came at horrific human cost; a \"city built on bones\" as countless laborers perished. Though Peter himself died before its gleaming gold spire rose, his magnificent city endured.\n",
            "\n",
            "Henry VII's precarious throne faced a brazen challenge on **24 May 1487**, when ten-year-old Lambert Simnel, a tradesman's son, was crowned 'king' in Dublin. This audacious Yorkist plot, orchestrated by a cunning priest, claimed Simnel was the escaped Earl of Warwick ‚Äì a deception Henry knew to be false. Nevertheless, the ambitious Earl of Kildare embraced the charade. Simnel, adorned with a circlet, was paraded through Dublin. Yet, this improbable rebellion swiftly crumbled at Stoke Field. In a remarkable twist of clemency, young Simnel was spared, finding a new life first in the king's kitchens, then as a falconer.\n",
            "\n",
            "On **25 May 1895**, Oscar Wilde plummeted from literary eminence into a public abyss, convicted of \"gross indecency.\" His tragic downfall began with an ill-fated libel suit against the Marquess of Queensberry, whose accusation of \"posing somdomite\" swiftly backfired. As the defense revealed witnesses, Wilde abandoned his case, only to be immediately arrested. After a hung jury in the first trial, a second, intensely publicized Old Bailey trial sealed his fate. The \"guilty\" verdict on May 25th plunged Wilde into horror. Justice Wills delivered a scathing condemnation, sentencing him to two years hard labor, crushing the flamboyant writer.\n",
            "\n",
            "May's historical tapestry features other pivotal moments: The valiant Dresden May Uprising, a final gasp of the 1848 revolutions, was brutally suppressed on **3 May 1849**. Poland's academic future was forged on **12 May 1364** with the founding of the prestigious Jagiellonian University. A somber note sounds on **19 May 1536**, with the tragic execution of the enigmatic Anne Boleyn. Imperial ambition shone bright on **26 May 1805** as Napoleon claimed the Iron Crown of Italy. A cosmic leap occurred on **30 May 1966**, with America's first lunar landing via Surveyor 1. Lastly, modern conflict brought tragedy on **15 May 1982**, as HMS Coventry was lost in the Falklands War, claiming 20 lives.\n",
            "Generated Summary: The General Strike of May 4, 1926, ignited by the Trades Union Congress' order for striking workers to go on strike, initially paralyzing Britain, was widely predicted to spark a Bolshevik revolution. However, the widely predicted unrest failed to materialize, instead transforming into a largely non-event, hailed by King George V as a tribute to British unity nine days later.\n",
            "\n",
            "On May 6, 1527, the devastating sack of Rome by the Holy Roman Emperor's imperial army, led by the notoriously ruthless Duke of Bourbon, ignited a global sensation. Disastrously, the duke was shot and killed almost immediately, leading to an orgy of plunder and vandalism, with the Swiss Guard making a desperate last stand against Pope Clement VII, their captain cut down in full view of his wife, and at least 12,000 people murdered in the ensuing carnage. In the early 16th century, Italy was a dangerous place, torn apart by ongoing wars between French and Spanish kings, and Rome had become a byword for massacres, plunder, and rapine.\n",
            "\n",
            "\n",
            "\n",
            "--- Example 4 ---\n",
            "Source Type: magazine\n",
            "Original Text: Cleopatra was the last of the Egyptian pharaohs. Her passing marked the end of the Ptolemaic dynasty, which had ruled Egypt since 305/304 BC, following the collapse of the empire established by Alexander the Great. It also enabled Octavian, who in 27 BC would become Augustus, the first Roman emperor, to get his hands on her lands. Ad Cleopatra had a history of staking the fortunes of her nation on Roman men. Firstly, she plumped for Julius Caesar and then, following his assassination, his staunc ...\n",
            "Target Summary: Cleopatra VII, the last pharaoh to grace the throne of ancient Egypt, marked the dramatic conclusion of the Ptolemaic dynasty and ushered in an era of Roman dominion. Her reign was defined by audacious political gambles, as she sought to secure her nation's future through alliances with towering Roman figures, notably Julius Caesar and, following his assassination, Mark Antony. This precarious balancing act ultimately collapsed with the inexorable rise of Octavian.\n",
            "\n",
            "Together, Antony and Cleopatra boldly challenged Octavian's ascent, their combined forces clashing in the climactic naval showdown at Actium. Their devastating defeat compelled a desperate flight back to Egypt. As Octavian's victorious legions advanced on Alexandria, a final, poignant tragedy unfolded. Mark Antony, receiving mistaken reports of Cleopatra's death, valiantly fell upon his sword in despair. Mortally wounded, he was carried to the queen's sanctuary, where, with his last breaths, he urged her to make peace. However, Cleopatra, fiercely resolute against the ultimate humiliation of a Roman triumphal parade, orchestrated her own final act, legendarily embracing a venomous asp alongside her loyal handmaidens. Her dramatic suicide, though momentarily dimming Octavian's triumphal glow, undeniably solidified his absolute power over Egypt. The transformed Roman province of Aegyptus, with its prodigious grain harvests and the bustling port of Alexandria, rapidly became a vital Roman breadbasket and economic hub, remaining under Roman rule for centuries.\n",
            "Generated Summary: Cleopatra, the last Egyptian pharaoh, died in 304 BC, marking the end of the Ptolemaic dynasty and the beginning of the Roman Empire under Octavian. She had a history of staking her fortunes on Roman men, first with Julius Caesar, then with her staunch supporter Mark Antony, who would later become Augustus, the first Roman emperor.\n",
            "\n",
            "Her final act, however, proved beyond even her legendary powers of persuasion. After their epic battle at the legendary battle of Actium in Greece, she hid herself in her mausoleum with her treasure and two maidservants, leaving Antony to fall upon his sword. When he discovered her, distraught and wounded, he asked her to make peace, but she refused. Deciding to commit suicide, legend has it she encouraged a snake to bite her, although her two handmaidens died at the same time, suggesting some other form of poisoning saw her off.\n",
            "\n",
            "\n",
            "--- Example 5 ---\n",
            "Source Type: newspaper\n",
            "Original Text: Smasher of Napoleon's invasion dream, veteran of three major wars, and scene of the death of the Royal Navy's greatest hero, HMS Victory is one of Britain's most famous warships. Curiously, and despite being on permanent display as a tourist attraction, Victory remains to this day a fully commissioned naval vessel. This is her story. A First-Rate Warship HMS Victory was constructed from 1759 at Chatham Dockyards in Kent to a design by Sir Thomas Slade. Built of solid oak and elm, the ship requir ...\n",
            "Target Summary: HMS Victory, a first-rate warship built between 1759 and 1765, was the largest ship yet constructed for the Royal Navy and bristled with over 100 guns. As Vice-Admiral Lord Nelson's flagship, she played a crucial role in the 1805 Battle of Trafalgar, which scuppered Napoleon's invasion dream and where Nelson was fatally wounded on board. Restored and opened to the public in 1928, HMS Victory remains a fully commissioned naval vessel and a prominent tourist attraction in Portsmouth today.\n",
            "Generated Summary: HMS Victory, constructed in 1759 and completed in 1765, was Britain's largest and most powerful naval vessel, capable of carrying over 800 men and bristling with over 100 guns. During the American Revolutionary War, she served as the flagship of Vice-Admiral Lord Hood and was instrumental in the crucial Battle of Trafalgar in 1805, a crucial naval battle that established the Royal Navy as the world's foremost naval fleet. After a lengthy decline as a prison hulk in 1797, Victory was extensively refitted in 1799 following the loss of HMS Imp\n",
            "\n",
            "\n",
            "ROUGE Scores:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'numpy.float64' object has no attribute 'mid'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2471361328.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ROUGE Scores:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{key}: {results[key].mid.fmeasure:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'mid'"
          ]
        }
      ]
    }
  ]
}