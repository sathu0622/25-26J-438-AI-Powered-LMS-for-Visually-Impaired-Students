{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZDeTPYSJYQ/C6/xLRo9lA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sathu0622/25-26J-438-AI-Powered-LMS-for-Visually-Impaired-Students/blob/AI-Powered-System-for-Voice-Based-Resource-Type-Summarization-of-Historical-Content-for-VIS/Fuction_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7Hc7kp9Dgur",
        "outputId": "388486f8-7cd3-4273-b027-3363a53e502e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 1️⃣ INSTALL DEPENDENCIES\n",
        "# ============================================================\n",
        "!apt-get update\n",
        "!apt-get install -y tesseract-ocr\n",
        "!pip install pytesseract pdf2image opencv-python pillow transformers torch tensorflow textblob\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpF6eAx-EI3P",
        "outputId": "7b7d2575-d55f-4784-ea45-afdf8e52dcf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 https://cli.github.com/packages stable InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,196 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,508 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,081 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,842 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,901 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.8 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,571 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,286 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,281 kB]\n",
            "Fetched 37.8 MB in 5s (7,834 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 65 not upgraded.\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.12/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (1.5.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytesseract, pdf2image\n",
            "Successfully installed pdf2image-1.17.0 pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HuQMiOjDee9",
        "outputId": "0cc9c0af-cc36-43be-c8e9-46eb79f3c3d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "{\n",
            "  \"resource_type\": \"newspapers\",\n",
            "  \"confidence\": 0.6855810284614563,\n",
            "  \"extracted_text\": \"The President said that the Bank of Botswana, during their 50th Anniversary, unveiled a commemorative P50 note bearing the names of the athletes, and that the team was a living example of resilience. “And so, on that rainy night in Tokyo, when others feared the\",\n",
            "  \"summaries\": [\n",
            "    \"During their 50th anniversary, the Bank of Botswana unveiled a commemorative P50 note bearing the names of the athletes. The team was a living example of resilience, and on that rainy night in Tokyo, others feared the rain.\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 2️⃣ IMPORTS\n",
        "# ============================================================\n",
        "import cv2\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, T5Tokenizer, T5ForConditionalGeneration\n",
        "import re\n",
        "\n",
        "pytesseract.pytesseract.tesseract_cmd = \"/usr/bin/tesseract\"\n",
        "\n",
        "# ============================================================\n",
        "# 3️⃣ OCR EXTRACTION\n",
        "# ============================================================\n",
        "def ocr_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    raw_text = pytesseract.image_to_string(img_rgb, lang=\"eng\")\n",
        "    return raw_text\n",
        "\n",
        "def ocr_pdf(pdf_path):\n",
        "    pages = convert_from_path(pdf_path)\n",
        "    text_pages = []\n",
        "    for i, page in enumerate(pages):\n",
        "        temp_img = f\"/content/temp_page_{i}.png\"\n",
        "        page.save(temp_img, \"PNG\")\n",
        "        text_pages.append(ocr_image(temp_img))\n",
        "        os.remove(temp_img)\n",
        "    return \" \".join(text_pages)\n",
        "\n",
        "def extract_text(input_path):\n",
        "    if input_path.lower().endswith(\".pdf\"):\n",
        "        return ocr_pdf(input_path)\n",
        "    else:\n",
        "        return ocr_image(input_path)\n",
        "\n",
        "# ============================================================\n",
        "# 4️⃣ TRANSFORMER-BASED OCR + GRAMMAR CORRECTION\n",
        "# ============================================================\n",
        "grammar_model_name = \"prithivida/grammar_error_correcter_v1\"\n",
        "grammar_tokenizer = AutoTokenizer.from_pretrained(grammar_model_name)\n",
        "grammar_model = AutoModelForSeq2SeqLM.from_pretrained(grammar_model_name)\n",
        "\n",
        "def correct_text(text):\n",
        "    inputs = grammar_tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    outputs = grammar_model.generate(inputs['input_ids'], max_length=1024)\n",
        "    corrected_text = grammar_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return corrected_text\n",
        "\n",
        "# ============================================================\n",
        "# 5️⃣ RESOURCE TYPE DETECTION MODEL\n",
        "# ============================================================\n",
        "IMG_SIZE = (224, 224)\n",
        "class_names = ['Books', 'Magazine', 'Newspapers']\n",
        "type_model_path = \"/content/drive/MyDrive/Image/book_magazine_newspaper_model_super_finetuned2.keras\"\n",
        "type_model = load_model(type_model_path)\n",
        "\n",
        "def predict_resource_type(img_path):\n",
        "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
        "    arr = image.img_to_array(img) / 255.0\n",
        "    arr = np.expand_dims(arr, 0)\n",
        "    pred = type_model.predict(arr)\n",
        "    cls = class_names[np.argmax(pred)]\n",
        "    conf = float(np.max(pred))\n",
        "    return cls.lower(), conf\n",
        "\n",
        "# ============================================================\n",
        "# 6️⃣ T5 SUMMARIZATION MODEL\n",
        "# ============================================================\n",
        "summ_model_path = \"/content/drive/MyDrive/t5_summarization_model/checkpoint-1715\"\n",
        "summ_tokenizer = T5Tokenizer.from_pretrained(summ_model_path)\n",
        "summ_model = T5ForConditionalGeneration.from_pretrained(summ_model_path)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "summ_model.to(device)\n",
        "\n",
        "def get_prefix(type_name):\n",
        "    if type_name == \"newspapers\":\n",
        "        return \"summarize: short summary: \"\n",
        "    elif type_name == \"magazine\":\n",
        "        return \"summarize: medium summary: \"\n",
        "    elif type_name == \"books\":\n",
        "        return \"summarize: long summary in detail: \"\n",
        "    return \"summarize: \"\n",
        "\n",
        "def summarize_text(text, source_type):\n",
        "    prefix = get_prefix(source_type)\n",
        "    input_text = prefix + text\n",
        "\n",
        "    inputs = summ_tokenizer(\n",
        "        input_text,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=1024,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    ).to(device)\n",
        "\n",
        "    output_ids = summ_model.generate(\n",
        "        inputs['input_ids'],\n",
        "        attention_mask=inputs['attention_mask'],\n",
        "        max_length=300,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    return summ_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# ============================================================\n",
        "# 7️⃣ SPLIT NEWSPAPER INTO ARTICLES\n",
        "# ============================================================\n",
        "def split_into_articles(text):\n",
        "    paragraphs = re.split(r'\\n{1,2}', text)\n",
        "    blocks = []\n",
        "    current_block = \"\"\n",
        "    for p in paragraphs:\n",
        "        if len(p.strip()) == 0:\n",
        "            continue\n",
        "        if re.match(r'^[A-Z0-9]{2,}', p.strip()):\n",
        "            if current_block:\n",
        "                blocks.append(current_block.strip())\n",
        "            current_block = p.strip()\n",
        "        else:\n",
        "            current_block += \" \" + p.strip()\n",
        "    if current_block:\n",
        "        blocks.append(current_block.strip())\n",
        "    return blocks\n",
        "\n",
        "# ============================================================\n",
        "# 8️⃣ FULL PIPELINE (NO ATHLETES/MEDALS)\n",
        "# ============================================================\n",
        "def process_document(input_path):\n",
        "    # Step 1: Extract raw text\n",
        "    raw_text = extract_text(input_path)\n",
        "\n",
        "    # Step 2: Correct OCR + grammar\n",
        "    corrected_text = correct_text(raw_text)\n",
        "\n",
        "    # Step 3: Detect resource type\n",
        "    if input_path.lower().endswith(\".pdf\"):\n",
        "        page = convert_from_path(input_path)[0]\n",
        "        temp_img = \"/content/temp_detect.jpg\"\n",
        "        page.save(temp_img, \"JPEG\")\n",
        "        resource_type, conf = predict_resource_type(temp_img)\n",
        "        os.remove(temp_img)\n",
        "    else:\n",
        "        resource_type, conf = predict_resource_type(input_path)\n",
        "\n",
        "    # Step 4: Split if newspaper\n",
        "    articles = split_into_articles(corrected_text) if resource_type == \"newspapers\" else [corrected_text]\n",
        "\n",
        "    # Step 5: Summaries\n",
        "    summaries = [summarize_text(art, resource_type) for art in articles]\n",
        "\n",
        "    # Step 6: FINAL JSON (clean)\n",
        "    final_output = {\n",
        "        \"resource_type\": resource_type,\n",
        "        \"confidence\": conf,\n",
        "        \"extracted_text\": corrected_text,\n",
        "        \"summaries\": summaries\n",
        "    }\n",
        "\n",
        "    return json.dumps(final_output, ensure_ascii=False, indent=2)\n",
        "\n",
        "# ============================================================\n",
        "# 9️⃣ RUN EXAMPLE\n",
        "# ============================================================\n",
        "input_file = \"/content/page_151.jpg\"\n",
        "result = process_document(input_file)\n",
        "print(result)\n"
      ]
    }
  ]
}