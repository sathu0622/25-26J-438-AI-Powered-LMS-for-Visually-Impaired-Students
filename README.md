# ğŸ“˜ AI-Powered Document Processing & Summarization Backend

## ğŸ“Œ Project Overview

This project implements an **AI-powered backend system** for extracting and summarizing historical content from **Books, Magazines, and Newspapers**.  
The system is specially designed to support **visually impaired students** by generating **clear, structured, and voice-friendly summaries**.

The backend automatically:
- Extracts text using OCR
- Detects the resource type
- Applies context-aware summarization using a **LoRA fine-tuned FLAN-T5 model**

---

## ğŸ¯ Key Features

- ğŸ“„ Supports **PDF and Image documents**
- ğŸ” OCR-based text extraction (without grammar correction)
- ğŸ§  Automatic resource type detection (Book / Magazine / Newspaper)
- ğŸ“° Article splitting for newspapers
- âœï¸ Context-aware summarization
- ğŸš€ FastAPI backend
- ğŸ’¾ Lightweight LoRA model (~25â€“100MB)

---

## ğŸ§  System Architecture

User Upload (PDF / Image)
          â†“
FastAPI Backend
          â†“
OCR (Tesseract)
          â†“
Resource Type Detection (CNN)
          â†“
Article Segmentation (Newspapers)
          â†“
FLAN-T5 + LoRA Summarization
          â†“
JSON Output (Voice-ready)


---

## ğŸ› ï¸ Technologies Used

### Backend
- Python 3.9+
- FastAPI
- PyTorch
- TensorFlow / Keras
- OpenCV
- Tesseract OCR
- Poppler (PDF to Image)

### AI Models
- CNN (Keras) â€“ Resource type classification
- FLAN-T5-Base (Google)
- LoRA (PEFT) â€“ Parameter-efficient fine-tuning

---

## ğŸ“‚ Project Structure


project-root/
â”‚
â”œâ”€â”€ Model/
â”‚ â”œâ”€â”€ book_magazine_newspaper_model_super_finetuned_FIXED.keras
â”‚ â””â”€â”€ final/ # FLAN-T5 + LoRA adapter
â”‚
â”œâ”€â”€ main.py # FastAPI backend
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt



---

## âš™ï¸ Model Details

### ğŸ”¹ Resource Type Classifier
- CNN-based image classification model
- Classes:
  - Books
  - Magazine
  - Newspapers
- Input size: 224 Ã— 224

### ğŸ”¹ Summarization Model
- Base model: `google/flan-t5-base`
- Fine-tuning method: LoRA (PEFT)
- Trainable parameters: ~2.7%
- Checkpoint size: ~25â€“100MB
- Evaluation Results:
  - ROUGE-1: 49.38
  - ROUGE-2: 20.85
  - ROUGE-L: 30.80

---

## ğŸ§ª OCR Module

- Uses **Tesseract OCR**
- Supports scanned images and PDFs
- Converts PDFs to images before OCR
- No grammar correction (intentional design)
- Preserves raw extracted content

---

## âœï¸ Summarization Strategy

Summarization behavior depends on the detected resource type:

| Resource Type | Summary Style |
|--------------|--------------|
| Newspaper | Short and factual |
| Magazine | Medium-length descriptive |
| Book | Long and detailed |

Example prompts:


---

## ğŸ”Œ API Endpoints

### âœ… Health Check


Response:
```json
{
  "status": "ok",
  "message": "Simplified Document Processor API v2.0"
}
```

ğŸ“¤ Process Document
POST /process
Supported file types:
PDF
JPG / JPEG
PNG
TIFF
BMP

{
  "resource_type": "newspapers",
  "confidence": 0.92,
  "extracted_text": "...",
  "summaries": [
    "Summary 1",
    "Summary 2"
  ],
  "num_articles": 4,
  "text_length": 12540
}

How to Run the Server
1ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

2ï¸âƒ£ Install OCR Tools

Install Tesseract OCR

Install Poppler for PDF support

3ï¸âƒ£ Start the Server
python main.py

ğŸ‘©â€ğŸ¦¯ Accessibility Use Case
Automatically understands document type
Produces clean summaries suitable for TTS
Enables independent learning for visually impaired users
Reduces cognitive load through structured summarization

ğŸ§‘â€ğŸ“ Research Contribution
This project contributes:
Resource-typeâ€“aware summarization
Lightweight fine-tuned language model using LoRA
OCR-driven historical document understanding
Accessibility-focused AI system design

ğŸš€ Future Enhancements
Voice-based interaction
Multilingual OCR and summarization
Audio navigation by sections
Mobile and web application integration

